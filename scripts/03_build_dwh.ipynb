{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa560df2-2938-4208-84fd-6e1e2f7c917b",
   "metadata": {},
   "source": [
    "# Create DWH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646d56a0-efb9-4a4c-927f-3907800c2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8303741b-aaef-4340-af94-aa4c8edf7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absoluten Pfad zum Projektverzeichnis und 'data-lake' Verzeichnis festlegen\n",
    "PROJECT_DIR = os.path.dirname(os.getcwd())  # Eine Ebene nach oben vom 'scripts'-Ordner\n",
    "DATA_LAKE_DIR = os.path.join(PROJECT_DIR, \"data-lake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8194b139-3544-47ea-9052-a294d68ca901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html_file(filename, encoding=\"utf-8\"):\n",
    "    full_path = os.path.join(PROJECT_DIR, filename)    \n",
    "    try:\n",
    "        # Versuch, die Datei mit der angegebenen Kodierung zu lesen\n",
    "        with open(full_path, \"r\", encoding=encoding) as f:\n",
    "            text = f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        # Fallback auf ISO-8859-1, falls UTF-8 fehlschlägt\n",
    "        #print(f\"Warnung: Kodierung {encoding} fehlgeschlagen für {filename}, versuche iso-8859-1\")\n",
    "        with open(full_path, \"r\", encoding=\"iso-8859-1\") as f:\n",
    "            text = f.read()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26381d3f-87a5-4405-a02a-dde32bd0f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(DATA_LAKE_DIR, \"2023-04-01-faz.html\")\n",
    "name = \"faz\"\n",
    "date = \"2022-04-01\"\n",
    "encoding = \"utf-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976fa4db-492d-45b0-b432-68e4ffd9626b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab',\n",
       " 'aber',\n",
       " 'abermaliges',\n",
       " 'abermals',\n",
       " 'abgerufen',\n",
       " 'abgerufene',\n",
       " 'abgerufener',\n",
       " 'abgerufenes',\n",
       " 'abgesehen',\n",
       " 'acht',\n",
       " 'aehnlich',\n",
       " 'aehnliche',\n",
       " 'aehnlichem',\n",
       " 'aehnlichen',\n",
       " 'aehnlicher',\n",
       " 'aehnliches',\n",
       " 'aehnlichste',\n",
       " 'aehnlichstem',\n",
       " 'aehnlichsten',\n",
       " 'aehnlichster']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_url = \"https://raw.githubusercontent.com/solariz/german_stopwords/master/german_stopwords_full.txt\"\n",
    "stopwords_list = requests.get(stopwords_url, allow_redirects=True).text.split(\"\\n\")[9:]\n",
    "stopwords_list[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f967c8-2429-4270-83dc-1ed2028868c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(name, date, file_name, encoding):\n",
    "    content = read_html_file(file_name, encoding)\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    text = soup.text\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    items = text.replace(\"\\n\", \" \").lower().split(\" \")\n",
    "    items = [i for i in items if len(i) > 1 and i not in stopwords_list]\n",
    "    item_count = pd.Series(items).value_counts()\n",
    "    count = item_count.to_frame()\n",
    "    count.columns = [\"count\"]\n",
    "    count[\"word\"] = count.index\n",
    "    count[\"paper\"] = name\n",
    "    count[\"date\"] = date\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ce5dc0-0ebe-47e5-ba05-88e407e3f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = parse_html(name, date, file_name, encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c951c2c7-20b8-4fd7-acd2-5715628304cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>paper</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blogs</th>\n",
       "      <td>3</td>\n",
       "      <td>blogs</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <td>1</td>\n",
       "      <td>subject</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krieges</th>\n",
       "      <td>1</td>\n",
       "      <td>krieges</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>außenpolitik:</th>\n",
       "      <td>1</td>\n",
       "      <td>außenpolitik:</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>straße.</th>\n",
       "      <td>1</td>\n",
       "      <td>straße.</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wirtschaft</th>\n",
       "      <td>8</td>\n",
       "      <td>wirtschaft</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do?</th>\n",
       "      <td>1</td>\n",
       "      <td>do?</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paternoster-posern</th>\n",
       "      <td>1</td>\n",
       "      <td>paternoster-posern</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bohrhammer</th>\n",
       "      <td>1</td>\n",
       "      <td>bohrhammer</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cartoons</th>\n",
       "      <td>1</td>\n",
       "      <td>cartoons</td>\n",
       "      <td>faz</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count                word paper        date\n",
       "blogs                   3               blogs   faz  2022-04-01\n",
       "subject                 1             subject   faz  2022-04-01\n",
       "krieges                 1             krieges   faz  2022-04-01\n",
       "außenpolitik:           1       außenpolitik:   faz  2022-04-01\n",
       "straße.                 1             straße.   faz  2022-04-01\n",
       "wirtschaft              8          wirtschaft   faz  2022-04-01\n",
       "do?                     1                 do?   faz  2022-04-01\n",
       "paternoster-posern      1  paternoster-posern   faz  2022-04-01\n",
       "bohrhammer              1          bohrhammer   faz  2022-04-01\n",
       "cartoons                1            cartoons   faz  2022-04-01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd6247b-1e79-4f17-b8f1-7233fb35279c",
   "metadata": {},
   "source": [
    "## HTML-Dateien iterieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2ffced-61bd-4545-8c0c-70eba5009a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings zum Behalten\n",
    "strings_to_keep = ['sz','zeit','faz', 'tagesspiegel', 'taz', 'abendblatt', 'berliner', 'welt', 'esslinger', 'handelsblatt', 'ntv', 'pioneer', 'suedwest', 'stuttgarter', 'dlf', 'dw-de', 'spiegel', 'mm', 'stern', 'tagesschau', 'wiwo', 'watson-de']\n",
    "\n",
    "# Durchlaufen aller CSV-Dateien im Verzeichnis\n",
    "for filename in os.listdir(DATA_LAKE_DIR):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(DATA_LAKE_DIR, filename)\n",
    "\n",
    "        # CSV-Datei mit Pandas einlesen\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Behalten nur der Zeilen, die den angegebenen Strings in der Spalte \"name\" enthalten\n",
    "        df = df[df['name'].isin(strings_to_keep)]\n",
    "\n",
    "        # Speichern der bearbeiteten CSV-Datei\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce0285e8-20c6-4f5b-bf5a-90897148f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_file(csv_file_name, sql_con=None):\n",
    "    df = pd.read_csv(csv_file_name)\n",
    "    if sql_con:\n",
    "        df.to_sql(\"log\", con=sql_con, if_exists=\"append\")\n",
    "    for i, row in df.iterrows():\n",
    "        name = row[\"name\"] \n",
    "        file_name = row[\"file_name\"]\n",
    "        date = row[\"date\"]\n",
    "        encoding = row[\"encoding\"]\n",
    "        count = parse_html(name, date, file_name, encoding)\n",
    "        if sql_con:\n",
    "            count.to_sql(\"count\", con=sql_con, if_exists=\"append\")\n",
    "        #print(name, date)\n",
    "        #print(count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6cc700e-e467-413b-8589-d02b25e00390",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = os.path.join(DATA_LAKE_DIR, \"2023-04-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f8a6cd2-a918-42bc-a745-84eb70bd1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_csv_file(csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16393d34-0260-4607-8581-554582b1db4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65def5b7-fdb3-4b67-a2b9-f36419e170b0",
   "metadata": {},
   "source": [
    "## CSV-files iterieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebe3e5dd-634f-4370-9ceb-da58f7b55f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename_list = glob(os.path.join(DATA_LAKE_DIR, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e9ba910-d581-4078-a41f-40def6f9351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_con = sqlite3.connect(os.path.join(PROJECT_DIR, \"db.sqlite3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "203028af-5812-4eb1-9ce1-e74ca8da0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_filename_list:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    #print(csv_file)\n",
    "    #print(len(df))\n",
    "    parse_csv_file(csv_file, sql_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd2dcdd-363d-4164-b90f-c76ed6ea786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376f3ed-55be-4824-85a0-012668957147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
